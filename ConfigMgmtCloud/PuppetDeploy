

Manifest files are where we store the rules to be applied, 
those extensions end with .pp



using a stand-alone Puppet, the same computer processes the facts, calculates the rules that need to be applied, and makes any necessary changes locally. So to get started with our Puppet deployment, let's first install Puppet and then we can start experimenting with running rules locally. In later videos, we'll check out how to create a client-server deployments. As we've called out, Puppet is available on a number of different platforms. We can either install it from the package management system available in the OS or download it from the official website.

For this exercise, we'll just go with the Puppet packages provided by the Ubuntu distribution. We'll do that by installing the Puppet master package using sudo apt install puppet-master.

We now have the package installed and can start trying out a few rules. We'll begin by creating the simplest possible Puppet file. We can make it more complex as we improve our deployments. For this example, we want to use Puppet to make sure that some useful tools for debugging problems are installed on each computer in our fleet.

we'll create a new file called tools.pp and in this file, we'll create a package resource. We'll start by managing the htop package which is a tool similar to top that can show us some extra information.

When declaring resources initially, we type the resource type in lowercase. When we reference a resource relationship from another file, we capitalize the resource name being referenced.

We'll state that we want Puppet to ensure that we have this package present on our computer. Cool. That was simple. That's all we have to do. This resource will take care of installing the package for us. Let's save the file and try it out. But before actually applying the rules, we want to check that the command isn't present yet. Htop isn't installed yet. Let's fix that by running our rules using sudo puppet apply -v tools.pp. The -v flag tells Puppet that we want to get verbose output which will tell us what's going on while Puppet is applying the rules in the file that we pass to it. So here, Puppet first told us that it was loading the facts. Then, that it compiled a catalog. After that, it told us that it was applying the current configuration. Then, that it installed the package we requested.

For example, if a packet should only be installed when a certain condition is met, this condition is evaluated on the server side based on the gathered facts. The catalog is the list of rules that are generated for one specific computer once the server has evaluated all variables, conditionals, and functions. In this example, the catalog will be exactly the same as our code because the code didn't include any variables, functions, or conditionals. More complex sets of rules can lead to different catalogs depending on fact values. It's now time to check if our rules actually works. Let's try running the htop command again now that Puppet has installed it for us. Yes, this time it worked. If our computer was misbehaving, we could now use this tool to get a better idea why. But fortunately, our computer's on its best behavior. So we'll exit now using q. Let's see what happens if we try to apply the Puppet rules again now that the package is installed.

Puppet's smart. It noticed that the package is already installed so it didn't try to install the package again


___________________________________________________-

View the ntp.pp manifest file by entering editing mode with the vim command. This file contains resources related to the NTP configuration: the ntp package, the ntp configuration file, and ntp service.

The relationships between these resources are also included in the code. In Puppet, code that defines a resource begins with a lowercase letter, whereas code that defines a relationship begins with a capital letter. The ntp configuration file requires the ntp package, which is indicated with the code require => Package['ntp']. The ntp service requires the ntp configuration file, which is indicated with the code require => File['/etc/ntp.conf']. Additionally, the ntp configuration file resource notifies the ntp service when it is present, which is indicated by the code notify  => Service['ntp']. 

The line include ntp indicates that the code will include the rules in this file as a class.


vim ntp.pp
class ntp {
  package { 'ntp':
    ensure => latest,
  } 
  file { '/etc/ntp.conf':
    source => '/home/user/ntp.conf',
    replace => true,
    require => Package['ntp'],
    notify  => Service['ntp'],
  }
  service { 'ntp':
    enable  => true,
    ensure  => running,
    require => File['/etc/ntp.conf'],
  }
}
include ntp

This code applies the rules from the ntp.pp file locally. The -v parameter specifies that the output should be verbose.

sudo puppet apply -v ntp.pp

Code output: 
The code output indicates that the package was created, checked whether the configuration file needed to be updated, and restarted the ntp service.


vim ntp.conf

driftfile /var/lib/ntp/ntp.drift
statistics loopstats peerstats clockstats
filegen loopstats file loopstats type day enable
filegen peerstats file peerstats type day enable
filegen clockstats file clockstats type day enable

server 0.pool.ntp.org
server 1.pool.ntp.org
server 2.pool.ntp.org
server 3.pool.ntp.org

restrict -4 default kod notrap nomodify nopeer noquery limited
restrict -6 default kod notrap nomodify nopeer noquery limited

restrict 127.0.0.1
restrict ::1

restrict source notrap nomodify noquery

View the ntp.pp manifest file by entering editing mode with the vim command. The lines beginning with “server” indicate that the NTP service uses servers from ntp.org. 

Writing the same code but modifying a few lines we update the servers to google servers:

server time1.google.com
server time2.google.com
server time3.google.com
server time4.google.com

This code applies the rules from the ntp.pp file locally, updates the configuration file with the new content from the file, then refreshes the service.

sudo puppet apply -v ntp.pp


ORGANIZING PUPPET MODULES


vim webserver.pp
include ::apache

View the webserver.pp manifest file by entering editing mode with the vim command. When the manifest file opens, it is blank. Add the line include ::apache. This code indicates that the Apache module should be included. The :: before apache indicates that it is a global module.


PUPPET NODES

node default {
  class { 'sudo': }
  class { 'ntp':
        servers => ['ntp1.example.com', 'ntp2.example.com']
  }
} /

The ABOVE command node default installs the sudo and ntp classes on all default nodes. The sudo class is installed with its default parameters, because no parameters are specified. The ntp class is installed with an additional parameter, indicated by servers => ['ntp1.example.com', 'ntp2.example.com'].


The BELOW  The command node webserver.example.com installs the sudo, ntp, and apache classes on nodes with the fully-qualified domain name (FQDN) webserver.example.com. 

Note: Because nodes with this FQDN have a specific set of classes that apply to them, the node default command will not apply any classes to them. 

node webserver.example.com {
  class { 'sudo': }
  class { 'ntp':
        servers => ['ntp1.example.com', 'ntp2.example.com']
  }
  class { 'apache': }
}

Node Definitions are when different kinds of nodes are defined,categorizing them and allowing different sets of rule catalogs to apply to different types of machines.

PUPPET SECURITY

Puppet uses public key infrastructure, or PKI, to establish secure connections between the server and the clients. There's a bunch of different types of public key technologies. The one used by Puppet is secure sockets layer or SSL. This is the same technology used for encrypting transmissions over HTTPS. The clients use this infrastructure to check the server's identity, and the server uses it to check the client's identity, and all communication is done over an encrypted channel that uses these identities so it can't be intercepted by other parties.

Each machine involved has a pair of keys related to each other, a private key and a public key. The private key is secret, only known to that specific machine, the public key is shared with other machines involved.

Machines can then use the standardized process to validate the identity of any other machine. The sender signs a message using the private key and the receiver validates the signature using the corresponding public key.

 The CA verifies the identity of the machine and then creates a certificate stating that the public key goes with that machine. After that, other machines can rely on that certificate to know that they can trust the public key, since it means the machine's identity has been verified. Puppet comes with its own certificate authority, which can be used to create certificates for each clients.

All sorts of things could go wrong if random computers start popping up in your network with the wrong settings. If you're creating a test deployment to try out how Puppet rules get applied, and so you're only managing test machines, you can configure Puppet to automatically sign all requests, but you should never do this for real computers being used by real users. Remember that it's better to be safe than sorry. So always take the time to authenticate your machines. When starting out with Puppet, it's common to use the manual signing approach. In this case, when the node connects to the master, it will generate a certificate request, which we'll go into a queue in the Puppet master machine. You'll then need to verify that the machine's identity is correct and the baked-in CA will issue the corresponding certificate. If your fleet is large, this manual approach won't really work. Instead, you'll want to write a script that verifies the identity of the machines automatically for you.

The Certificate Authority creates an SSL key for the agent machine and creates a certificate request.

One way to do this is by copying a unique piece of information into the machines when they get provisioned and then use this pre-shared data as part of the certificate request. That way, your script can verify that the machines are who they claim to be without involving any humans. Great, you now have a broad idea of the infrastructure that Puppet uses to identify the nodes when they connect to the master.

sudo puppet config --section master set autosign true

ssh webserver
sudo apt install puppet
sudo puppet config set server ubuntu.example.com

sudo puppet agent -v --test

This code tests the connection between the Puppet agent on the machine and the Puppet master. The -v command indicates that the output should be verbose, and the --test command indicates that this is a test run. 

________________________________________

MODIFYING MANIFESTS

This code runs an rspec test to determine whether the gksu package has the intended behavior when the fact is_virtual is set to false. When this is the case, the gksu package should have the ensure parameter set to latest: ensure('latest').

Here we're setting the is virtual fact to false. And then we asked the test infrastructure to verify that the gks you package is included with the insurer parameter set to latest tests.


describe 'gksu', :type => :class do
  let (:facts) { { 'is_virtual' => 'false' } }
  it { should contain_package('gksu').with_ensure('latest') }
end

 A simple first step is to use the puppet parser validate command that checks that the syntax of the manifests is correct on top of that we can also run the rules using the- - noop parameter the name comes from no operations and it makes puppet simulate what it would do without actually doing it. You can look at the list of actions that it would take and check that they're exactly what you wanted puppet to do.

 Tests like this one can be a useful way to check that. Our catalog is written correctly and they can be super helpful when a rule is used a lot of facts that interact with each other and we want to check that the result is actually what we intended. We can write a bunch of these tests and run them automatically whenever there is a change to the rules. This way we can be sure that the rules stay valid and know that the new changes didn't break the old rules, but that just checks that the catalog contains the rules that we set should contain. How can we verify that these rules actually have the effects we want like enabling the corporate website or setting up a strict firewall.

 