reading information from disk or transferring it over the network 
is a slow operation. In typical scripts while this operation is 
going on, nothing else happens. The script is blocked, waiting for 
input or output while the CPU sits idle. One way we can make this 
better is to do operations in parallel. That way, while the 
computer is waiting for the slow IO, other work can take place. 
The tricky part is dividing up the tasks so that we get the same 
result in the end. There's actually a whole field of computer 
science called concurrency, dedicated to how we write programs 
that do operations in parallel.


A script is CPU bound if you're running operations in parallel 
    using all available CPU time.  





Our company has an e-commerce website that includes a bunch of images of the products that are up for sale. There's a rebranding coming up, which means that all of these images will need to be replaced with new ones. This includes both the full-size images and the thumbnails. We have a script that creates the thumbnails based on the full-size images. But there's a lot of files to process, and our script is taking a long time to finish

Let's try making this go faster by having it process the images in parallel. We'll start by importing the futures sub module, which is part of the concurrent module. This gives us a very simple way of using Python threads.

To be able to run things in parallel, we'll need to create an executor. This is the process that's in charge of distributing the work among the different workers. The futures module provides a couple of different executors, one for using threads and another for using processes. We'll go with the ThreadPoolExecutor for now.

 the function that does most of the work in this loop is process_file. Instead of calling it directly in the loop, we'll submit a new task to the executor with the name of the function and its parameters.

 Our for loop now creates a bunch of tasks that are all scheduled in the executor. The executor will run them in parallel using threads. An interesting thing that happens when we use threads is that the loop will finish as soon as all tasks are scheduled.

 But it will still take a while until the tasks complete. So we'll add a message saying that we're waiting for all threads to finish, and then call the shutdown function on the executor. This function waits until all the workers in the pool are done, and only then shuts down the executor.

 